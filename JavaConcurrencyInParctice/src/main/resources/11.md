# 性能与伸缩性

## 对性能的思考

要针对性的思考性能问题，和硬件的冲突，不是一定要用多线程来处理问题。

### 性能与可伸缩性

可伸缩性是指：当增加计算资源时，程序当吞吐量或者处理能力得到相应的提高

进行性能条调优是用更小的代价来完成相同的工作。进行可伸缩性调优是将问题的计算并行化，从而利用更多资源完成更多工作。

### 评估各种性能权衡因素

## Amdahl定律

Amdahl定律：在增加计算资源的情况下，程序在理论上能够实现最高加速比，这个值取决于程序中可并行组件和串行组件所占的比重。

F为必须串行的比例，N为N个处理器。
SpeedUp <=  1 / F + (1-F) / N

因此N越大，越趋近于1 / F。 

见WorkerThread，假如多个线程共享一个队列，初看上去似乎能并行：各个任务之间不会等待，因此处理器越多，并发处理对任务就越多。然而，这个过程里还是包含
了一个串行部分---取任务（因此在对该队列进行并发访问时需要采用某种同步机制来维持队列的完整性，这里就发生了串行）。

### 示例：在各种框架下的隐藏的串行部分

要想知道串行部分的能力，可以比较增加线程时吞吐量的变化，并根据观察到的伸缩性判断串行部分的能力差异。一句话，util里原有的线程并发容器类性能最高！

### Amdahl的应用

锁分解（一个锁分解成二个锁）并不能利用多处理器的能力，锁分段反而能提升性能（因为分段的数量随着处理器数量的增加而增加）。当然某些情况下，将一个锁分解为
2个就够了

## 线程引入的开销

### 上下文切换的开销

### 内存同步

### 阻塞

自旋等待直到成功

## 减少锁的竞争

串行操作降低伸缩性，上下文切换也降低性能。锁上竞争同时触发这两种问题。

两个因素影响锁上竞争的可能性，锁的请求频率，以及锁持有的时间。

有3种方式降低竞争程度

1.  减少锁持有的时间
2.  降低锁的请求频率
3.  使用带有协调机制的独占锁，这些机制允许更高的并发性

### 缩小锁的范围（快进快出）

减少时间：见AttributeStore，见BetterAttributeStore

### 缩小锁的粒度

降低频率：锁分解和锁分段，问题：发生死锁的风险就越高

如果一个锁保护多个相互独立的变量，可以将锁分解为多个锁，每个锁只保护一个变量，从而提高伸缩性，从而降低频率。见ServerStatus,见BetterServerStatus

把竞争的锁分解

### 锁分段

对一组独立对象上的锁进行分解。缺点是，要获取多个锁来实现独占访问将更加困难且开销更大。
见StripedMap

### 避免热点域

如果使用锁分段，那么一定是在锁上的竞争频率高于锁保护的数据的竞争的频率。ServerStatus两个线程，一个访问user，一个访问query，并没有在数据上竞争，是在锁上竞争。

当操作涉及多个变量时，锁的粒度难以下降，这就会把反复计算的结果缓存起来，称之为"热点域"。这样的值在串行代码里优势很高，但是并行化就需要考虑数据安全。
因此ConcurrentHashMap中的size就是全局计算，而不是维护一个全局计数。

### 一些替代独占锁的方法

第三种方式就是放弃独占锁，例如使用并发容器，不可变对象以及原子变量

### 检测CPU的利用率

### 向对象池说不

## 示例：比较Map的性能

## 减少上下文切换的开销

阻塞和运行也是上下文切换。





